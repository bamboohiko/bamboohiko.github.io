---
title: 聚类(Cluster)
categories:
 - note
tags:
 - 数据挖掘
 - 聚类
---

聚类(*Cluste* )是一个将数据对象(*Objects* )集分为多个组(*groups* )或类(*clusters* )，使得同一类中的对象相似度高，而不同类的对象相似度低的过程

<!-- more -->

相似度一般用对象的属性值和距离来估算，比如欧氏距离(*Euclidian distance* )，余弦相似度(*Cosine similarity* )，或皮尔森相关系数(*Pearson Correlation* ) 。

主要的聚类算法可以分为三类：分区方式，分层方式，基于密度的方式。

1.  **分区方式**：将大小为$n$的对象集分为$k$个区，每个区作为一个分类且包含至少一个对象，分区算法是给定一个初始分类并移动对象的所属分类来进行迭代，主要有 *k-means* 算法 和 *k-medoids* 算法

2.  **分层方式**：将给定的对象集进行分层分解，产生一颗树形结构，通常有合并和分割两种方式，合并方式也叫做 *bottom-up* 方式，由单个对象开始合并直到合并为一个组或满足终止条件；分割方式也叫做 *top-down* 方式，从一个包含所有对象的类开始分割，直到分割为单个对象或满足结束条件。分层方式能被当做框架或是变换方式使用，在每一步分割或是合并中应用其他两种聚类方法（将一个类别当做一个对象来处理）

3.  **基于密度的方式**：基于对象距离的分区方式聚类只能做出球状的聚类，而基于密度的聚类能做出任意形状的聚类，这个聚类是在相邻密度超过临界值的前提下，通过增长一个给定的聚类所得到的，此类算法能滤除噪声和异常，此外为加速计算可以用划分的方格替代原对象空间，聚类操作在这个方格结构上运行。

---

## 分区聚类方式

---

分区聚类方式中最常用的 *k-means* 算法和 *k-medoids* 算法，$k$为类的数量。

### *k-means* 算法

1.  从对象集k中随机选择$k$个点作为初始的中心
2.  计算每个点到每个中心的距离，将这个点加到最近中心所代表的分类中
3.  计算每个类中所有点的中心点，即$\frac {\sum^n p} n$
4.  重复步骤2-3直到聚类不改变。

每次迭代的时间复杂度为$O(kn)$

code：<https://github.com/bamboohiko/urbanCompute/blob/master/cluster/k_mean.py>

### *k-medoids* 算法

*k-means* 算法对噪声非常敏感，在 *k-medoids* 对其所做的改进是，用类中的一个点而非类中点的中心点来代表一个类,同时每次迭代的时间复杂度会变为$O(k(n-k)^2)$：

PAM(*Partitioning Around Medoids* )算法：

同样地，PAM算法也是一个迭代的贪心算法，通过用一个非中心点来取代一个中心点，提高聚类的质量，例如用$cost_{i,j}$来表示将中心点$i$替换为非中心点$j$的代价变化，则有

>   $ cost_{i,j}=\sum_{k=1}^{n} d(k,j) - d(k,i) \ cluster_{before}k \neq cluster_{after}k $

算法的步骤如下：

1.  从对象集k中随机选择$k$个点作为初始的中心
2.  计算每个点到每个中心的距离，将这个点加到最近中心所代表的分类中
3.  计算所有中心点$i$替换为非中心点$j$的代价$cost_{i,j}$，选择其中最小的$cost_{i,j}$，将中心点$i$替换为非中心点$j$
4.  重复步骤2-3直到中心点不改变。

---

## 基于密度的方式

---
